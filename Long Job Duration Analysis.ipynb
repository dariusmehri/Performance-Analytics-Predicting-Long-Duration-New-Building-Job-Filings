{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JOB APPROVALS BIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = \"C:\\\\Users\\\\dmehri\\\\Documents\\\\DATA\\\\Long Job Duration\\\\\"\n",
    "\n",
    "df = pd.read_csv(path + \"Long Job Dur - Job Approvals - BIS.csv\", low_memory=False)\n",
    "df[\"Job Number\"] = df[\"Job Number\"].astype(str).map(str.strip)\n",
    "\n",
    "\n",
    "print (\"Only do anlaysis on NBs\")\n",
    "print (\"Length before drop\", len(df))\n",
    "df[\"Job Type\"] = df[\"Job Type\"].astype(str).map(str.strip)\n",
    "df = df[df[\"Job Type\"] == \"NB\"]\n",
    "print (\"Length after drop\", len(df))\n",
    "print (\"Drop pro-cert jobs\")\n",
    "df[\"Pro-Cert Description\"] = df[\"Pro-Cert Description\"].astype(str).map(str.strip)\n",
    "df = df[df[\"Pro-Cert Description\"] != \"Professionally Certified Application\"]\n",
    "print (\"Length after drop\", len(df))\n",
    "\n",
    "print (\"Drop BSA jobs\")\n",
    "df[\"BSA Calendar Number\"] = df[\"BSA Calendar Number\"].astype(str).map(str.strip)\n",
    "df = df[df[\"BSA Calendar Number\"] == \"nan\"]\n",
    "print (\"Length after drop\", len(df))\n",
    "\n",
    "print (\"Drop CPC jobs\")\n",
    "df[\"CPC Calendar Number\"] = df[\"CPC Calendar Number\"].astype(str).map(str.strip)\n",
    "df = df[df[\"CPC Calendar Number\"] == \"nan\"]\n",
    "print (\"Length after drop\", len(df))\n",
    "\n",
    "\n",
    "df = df.rename(columns={'D_DATE': 'App Process Date'})\n",
    "\n",
    "#df[\"Job Type\"] = df[\"Job Type\"].astype(str).map(str.strip)\n",
    "#df = df[df[\"Job Type\"] == \"NB\"]\n",
    "#print (\"len after drop\", len(df))\n",
    "\n",
    "print (\"Drop NAN in app process date\")\n",
    "print (\"len before drop\", len(df))\n",
    "df = df.dropna(subset = ['App Process Date'])\n",
    "print (\"len after drop\", len(df))\n",
    "\n",
    "\n",
    "\n",
    "df['Plan Approval Date'] = pd.to_datetime(df['Plan Approval Date'])\n",
    "#df['Plan Approval Date'] = df['Plan Approval Date'].apply(lambda x: x.date())\n",
    "df['App Process Date'] = pd.to_datetime(df['App Process Date'])\n",
    "#df['App Process Date'] = df['App Process Date'].apply(lambda x: x.date())\n",
    "\n",
    "#print (\"Subset for when appointments end in PENS BIS dataset, October 2018\")\n",
    "#end_time = str(10) + '-' + str(1) + '-' + str(2018)\n",
    "\n",
    "#mask = ( (df['App Process Date'] <= end_time) )\n",
    "\n",
    "#df = df.loc[mask]\n",
    "\n",
    "#print (\"length after date subset\", len(df))\n",
    "\n",
    "\n",
    "#df['Difference'] = (df['Plan Approval Date'] - df['App Process Date']).dt.days\n",
    "\n",
    "\n",
    "#pd.bdate_range(df['Plan Approval Date'],df['App Process Date'], freq = 'B')\n",
    "\n",
    "df[\"bussDays\"] = np.busday_count( df['App Process Date'].values.astype('datetime64[D]'), df['Plan Approval Date'].values.astype('datetime64[D]'))\n",
    "\n",
    "#df[\"bussDays\"] = df[\"bussDays\"].abs()\n",
    "print (\"drop buss days less than zero\", len(df))\n",
    "df = df[df[\"bussDays\"] >= 0].reset_index(drop=True)\n",
    "print (\"len after drop\", len(df))\n",
    "\n",
    "\n",
    "print (\"drop by job number, initial and approval date\")\n",
    "df = df.drop_duplicates(subset=['Job Number', 'Plan Approval Date', 'App Process Date']).reset_index(drop=True)\n",
    "print (\"len after drop\", len(df))\n",
    "\n",
    "\n",
    "numunique = list(set(df[\"Job Number\"].tolist() ))\n",
    "print (len(numunique))\n",
    "print (\"number of unique job numbers\", len(numunique))\n",
    "\n",
    "\n",
    "df[\"bussYears\"] = df[\"bussDays\"]/365.0\n",
    "\n",
    "\n",
    "columns = sorted(df.columns)\n",
    "\n",
    "\n",
    "#df[\"Filing Representative First Name\"] = df[\"Filing Representative First Name\"].astype(str).map(str.strip)\n",
    "#df[\"Filing Representative First Name\"] = df[\"Filing Representative First Name\"].map(str.upper)\n",
    "#df[\"Filing Representative Last Name\"] = df[\"Filing Representative Last Name\"].astype(str).map(str.strip)\n",
    "#df[\"Filing Representative Last Name\"] = df[\"Filing Representative Last Name\"].map(str.upper)\n",
    "#df[\"Filing Representative Name\"] = df[\"Filing Representative First Name\"] + \" \" + df[\"Filing Representative Last Name\"]\n",
    "\n",
    "\n",
    "#df[\"OT Description\"] = df[\"OT Description\"].astype(str).map(str.strip).map(str.upper)\n",
    "#df[\"OT Description\"] = df[\"OT Description\"].str.replace('.','')\n",
    "#df[\"OT Description\"] = df[\"OT Description\"].map(str.strip)\n",
    "\n",
    "\n",
    "print (\"Create stories category\")\n",
    "\n",
    "def StoriesCat(x):\n",
    "    if x < 7:\n",
    "        return \"Low Rise\"\n",
    "    if x >= 7:\n",
    "        return \"High Rise\"\n",
    "\n",
    "df[\"Stories Category\"] = df[\"Proposed Stories\"].apply(StoriesCat)\n",
    "\n",
    "\n",
    "\n",
    "print ()\n",
    "print (\"Work types\")\n",
    "#df = df.replace({'X': '1'}, regex=True)\n",
    "#df = df.replace({'Y': '1'}, regex=True)\n",
    "\n",
    "\n",
    "#COMMON WORK TYPES BETWEEN DOB NOW ANBD BIS\n",
    "#Boiler\n",
    "#Mechanical\n",
    "#Plumbing\n",
    "#Standpipe\n",
    "#Construction Equipment\n",
    "#General Construction\n",
    "#Curb Cut\n",
    "\n",
    "\n",
    "worktypesorig = ['Boiler Flag', 'Mechanical Flag',\n",
    "       'Plumbing Flag', 'Standpipe Flag',\n",
    "       'Construction Equipment Flag', 'General Construction Flag',\n",
    "       'Curb Cut Flag' ]\n",
    "\n",
    "\n",
    "for w in worktypesorig:\n",
    "    df[w] = df[w].str.replace('X', '1')\n",
    "    df[w] = df[w].str.replace('Y', '1')\n",
    "\n",
    "df = df.fillna('0')\n",
    "\n",
    "df = df.rename(columns={'Boiler Flag': 'Boiler', \n",
    "                        'Mechanical Flag': 'Mechanical',\n",
    "                       'Plumbing Flag':'Plumbing',\n",
    "                       'Standpipe Flag':'Standpipe',\n",
    "                       'Construction Equipment Flag':'Construction Equipment',\n",
    "                       'General Construction Flag':'General Construction',\n",
    "                       'Curb Cut Flag':'Curb Cut'})\n",
    "\n",
    "\n",
    "\n",
    "print (\"Drop fields not relevant for NB analysis\")\n",
    "dropfields = [\"Chute\", \"Fence\", \"Enlargement Flag (Yes/No)\",\n",
    "             \"Enlargement SQFT\", \"Construction Material\", \"Existing Stories\", \"Existing Zoning Floor Area\",\n",
    "             \"Existing Dwelling Units\", \"Estimated Job Cost\", \"Other Equipment Flag\", \"EQ Other Description\", \n",
    "             \"Supported Scaffold\", \"Sidewalk Shed\", \"Sidewalk Shed/Linear Feet\", \"Filing Representative Last Name\",\n",
    "             \"Filing Representative First Name\"]\n",
    "\n",
    "df = df.drop(dropfields, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"Clean occupancy\")\n",
    "occupancy = sorted(list(set(df[\"Proposed Occupancy Classification Description\"].tolist() )))\n",
    "print (\"len of plan examiners\", len(occupancy))\n",
    "print (sorted(occupancy) )\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('  ', ' ')\n",
    "#df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.split(\":\").str[0]\n",
    "#df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.split(\"(\").str[0]\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].map(str.strip)\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('EDUCATIONAL', 'EDUCATION')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('INSTITUTIONAL', 'INSTITUTION')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('RESIDENTIAL: 1 & 2 FAMILY HOUSES', 'RESIDENTIAL 1-2 FAMILY HOUSES')\n",
    "\n",
    "\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('ASSEMBLY: EATING & DRINKING', 'ASSEMBLY')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('ASSEMBLY: INDOOR SPORTS', 'ASSEMBLY')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('ASSEMBLY: OTHER', 'ASSEMBLY')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('ASSEMBLY: OUTDOORS', 'ASSEMBLY')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('ASSEMBLY: THEATERS, CONCERT HALLS', 'ASSEMBLY')\n",
    "\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('FACTORY/INDUSTRIAL: LOW HAZARD', 'FACTORY INDUSTRIAL')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('FACTORY/INDUSTRIAL: MODERATE HAZARD', 'FACTORY INDUSTRIAL')\n",
    "\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('HIGH HAZARD: ACCELERATED BURNING', 'HIGH HAZARD')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('HIGH HAZARD: HEALTH', 'HIGH HAZARD')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('HIGH HAZARD: SUPPORTS COMBUSTION', 'HIGH HAZARD')\n",
    "\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('INSTITUTION: ASSISTED LIVING', 'INSTITUTION')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('INSTITUTION: DAY CARE', 'INSTITUTION')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('INSTITUTION: INCAPACITATED', 'INSTITUTION')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('RESIDENTIAL APT HOUSE', 'RESIDENTIAL: APARTMENT HOUSES')\n",
    "\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('RESIDENTIAL APT HOUSE', 'RESIDENTIAL: APARTMENT HOUSES')\n",
    "\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('STORAGE (LOW HAZARD)', 'STORAGE')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('STORAGE: LOW HAZARD', 'STORAGE')\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('STORAGE: MODERATE HAZARD', 'STORAGE')\n",
    "\n",
    "df['Proposed Occupancy Classification Description'] = df['Proposed Occupancy Classification Description'].str.replace('RESIDENTIAL (HOTELS)', 'RESIDENTIAL: HOTELS, DORMITORIES')\n",
    "\n",
    "\n",
    "df[\"Applicant License Number\"] = df[\"Applicant License Number\"].astype(str).map(str.strip)\n",
    "df[\"Applicant Name\"] = df[\"Applicant First Name\"] + \" \" + df[\"Applicant Last Name\"]\n",
    "\n",
    "print ()\n",
    "occupancy = sorted(list(set(df[\"Proposed Occupancy Classification Description\"].tolist() )))\n",
    "print (\"len of plan examiners\", len(occupancy))\n",
    "print (sorted(occupancy))\n",
    "\n",
    "\n",
    "print (\"drop business days less than zero\", len(df))\n",
    "df2= df.copy()\n",
    "df2 = df2[df2[\"bussDays\"] > 0]\n",
    "#df2 = df2[df2[\"bussDays\"] <1000]\n",
    "print (\"len after drop\", len(df2))\n",
    "\n",
    "#print (\"Mean\", df2[\"bussDays\"].mean())\n",
    "#print (\"Standard deviation\", df2[\"bussDays\"].std())\n",
    "#print (\"Median\", df2[\"bussDays\"].median())\n",
    "#print ()\n",
    "#df2[\"bussDays\"].describe()\n",
    "\n",
    "\n",
    "print (\"Plan exam name\")\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].astype(str)\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('.', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('PLAN EXAMINER', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('PLAN EXAM', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('PLAN EXA', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('PLAN EX', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('S/C ACCESS', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('S/C EXAM', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('BRONX', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('BX', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('QUEENS', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' QNS', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' QN', ' ')\n",
    "\n",
    "\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' BORO COMM', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' CALL 311', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' CALL CTR 311', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' CALL CENTER', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' CALL CENTER', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('/BUILD IT BACK', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('/ BUILD IT BACK', ' ')\n",
    "\n",
    "\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('BROOKLYN', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' BK', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' (BKLYN)', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' MAN', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' S I', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' S/C', ' ')\n",
    "#df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' ()', '')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' - ', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' LYN', ' ')\n",
    "\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(' ONLY', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('(', '')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace(')', '')\n",
    "\n",
    "\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('   ', ' ')\n",
    "df['Plan Examiner BIS Name'] = df['Plan Examiner BIS Name'].str.replace('  ', ' ')\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Skewed Continus Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated Fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(df))\n",
    "df = df[df[\"J_TOTAL_ESTIMATED_FEE\"] < 1000000]\n",
    "print (len(df))\n",
    "\n",
    "\n",
    "df[\"EstFeeLogNorm\"] = np.log(df[\"J_TOTAL_ESTIMATED_FEE\"])\n",
    "estfeedesc = df[\"EstFeeLogNorm\"].describe()\n",
    "estfeedesc[7]\n",
    "df[\"EstFeeLogNorm\"] = df[\"EstFeeLogNorm\"]/estfeedesc[7]\n",
    "\n",
    "df[\"EstFeeLogNorm\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed Zoning Floor Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(df))\n",
    "df = df[df[\"Proposed Zoning Floor area\"] < 1000000]\n",
    "print (len(df))\n",
    "\n",
    "df[\"ZoningFloorLogNorm\"] = np.log(df[\"Proposed Zoning Floor area\"] + 1)\n",
    "estfeedesc = df[\"ZoningFloorLogNorm\"].describe()\n",
    "estfeedesc[7]\n",
    "df[\"ZoningFloorLogNorm\"] = df[\"ZoningFloorLogNorm\"]/estfeedesc[7]\n",
    "\n",
    "df[\"ZoningFloorLogNorm\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dwelling Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Proposed Dwelling Units\"] = df[\"Proposed Dwelling Units\"].astype(int)\n",
    "df[\"DwellUnitsLogNorm\"] = np.log(df[\"Proposed Dwelling Units\"] + 1)\n",
    "estfeedesc = df[\"DwellUnitsLogNorm\"].describe()\n",
    "estfeedesc[7]\n",
    "df[\"DwellUnitsLogNorm\"] = df[\"DwellUnitsLogNorm\"]/estfeedesc[7]\n",
    "df[\"DwellUnitsLogNorm\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(df))\n",
    "df = df[df[\"Floor Area Ratio (FAR)  Floor Area\"] < 900000]\n",
    "print (len(df))\n",
    "\n",
    "df[\"FARLogNorm\"] = np.log(df[\"Floor Area Ratio (FAR)  Floor Area\"] +1 )\n",
    "estfeedesc = df[\"FARLogNorm\"].describe()\n",
    "estfeedesc[7]\n",
    "df[\"FARLogNorm\"] = df[\"FARLogNorm\"]/estfeedesc[7]\n",
    "df[\"FARLogNorm\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(path + \"Long Job Duration BIS 2.csv\", index=False)\n",
    "\n",
    "df.to_csv(path + \"test.csv\", index=False)\n",
    "\n",
    "#df.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAN EXAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "pd.set_option('chained_assignment', None)\n",
    "\n",
    "da = pd.read_csv(path + \"Long Duration Plan Exam Report Darius.csv\", low_memory=False)\n",
    "print (len(da))\n",
    "\n",
    "da[\"J_JOB_NUMBER\"] = da[\"J_JOB_NUMBER\"].astype(str)\n",
    "\n",
    "#da2 = da[[\"Examiner Name\"]]\n",
    "#da2[\"Exam Count\"] = 1\n",
    "\n",
    "#daG = da2.groupby(['Examiner Name']).sum()\n",
    "#daG = daG.add_suffix('').reset_index()\n",
    "\n",
    "dac = da[[\"J_JOB_NUMBER\"]]\n",
    "dac[\"Plan Exam Count\"] = 1\n",
    "dac = dac.groupby(['J_JOB_NUMBER']).sum()\n",
    "dac = dac.add_suffix('').reset_index()\n",
    "\n",
    "\n",
    "dac = dac.sort_values(by = 'Plan Exam Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "dacDic = dac.set_index('J_JOB_NUMBER')['Plan Exam Count'].to_dict()\n",
    "\n",
    "df2[\"Plan Exam Count\"] = df2[\"Job Number\"].map(dacDic)\n",
    "\n",
    "print (\"Total number appointments after grouped\", dac[\"Plan Exam Count\"].sum() )\n",
    "print (\"Total number of appointments merged into df\", df2[\"Plan Exam Count\"].sum() )\n",
    "\n",
    "print (\"Drop job filings with nan plan exam counts\")\n",
    "df2 = df2.dropna(subset = ['Plan Exam Count'])\n",
    "\n",
    "print (\"len after drop\", len(df2))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAN EXAMINER ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dp = df2[[\"Plan Examiner BIS Name\", \"Plan Exam Count\"]]\n",
    "dp[\"Job Count\"] = 1\n",
    "\n",
    "dp2 = (dp.groupby('Plan Examiner BIS Name').agg({'Job Count':'sum', 'Plan Exam Count': 'sum'}).reset_index().rename(columns={'Job_Number':'Job_Number_count'}) )\n",
    "\n",
    "#dp = dp.groupby(['Plan Examiner BIS Name']).sum()\n",
    "#dp = dp.add_suffix('').reset_index()\n",
    "dp2[\"Avg Number Plan Exams\"] = dp2[\"Plan Exam Count\"]/dp2[\"Job Count\"]\n",
    "\n",
    "dp3 = (dp.groupby('Plan Examiner BIS Name').agg({'Plan Exam Count':'median'}).reset_index().rename(columns={'Job_Number':'Job_Number_count'}) )\n",
    "\n",
    "dp3Dic = dp3.set_index('Plan Examiner BIS Name')['Plan Exam Count'].to_dict()\n",
    "\n",
    "dp2[\"Median Number Plan Exams\"] = dp2[\"Plan Examiner BIS Name\"].map(dp3Dic)\n",
    "\n",
    "dp2[\"Above Upper Quartile\"] = \"No\"\n",
    "dp2[\"Above One Standard Dev\"] = \"No\"\n",
    "\n",
    "for i in range(0, len(dp2)):\n",
    "    if dp2[\"Median Number Plan Exams\"][i] > 8:\n",
    "        dp2[\"Above Upper Quartile\"][i] = \"Yes\"\n",
    "        \n",
    "    if dp2[\"Avg Number Plan Exams\"][i] > 10.7:\n",
    "        dp2[\"Above One Standard Dev\"][i] = \"Yes\"\n",
    "\n",
    "print (df2[\"Plan Exam Count\"].describe())\n",
    "\n",
    "#dp.to_csv\n",
    "dp2\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp2.to_csv(path + \"Plan Examiner Stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#da.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(path + \"test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (df2[\"Plan Exam Count\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(path + \"Long Job Duration BIS 2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df2 = df2.reset_index(drop=True)\n",
    "countzeros = ['Proposed Stories', 'Proposed Zoning Floor area', 'BIN Number',\n",
    "       'Lot Area (sqft)',\n",
    "       'J_BALANCE_DUE', 'Difference', 'bussDays', 'bussYears',\n",
    "       'Appointment Count',\"Proposed Dwelling Units\", \"Lot Area (sqft)\", \"Floor Area Ratio (FAR)  Floor Area\", \n",
    "        \"J_TOTAL_ESTIMATED_FEE\" ]\n",
    "\n",
    "for p in countzeros:\n",
    "    print (p)\n",
    "    dfcountzeros = df2.copy()\n",
    "    dfcountzeros = dfcountzeros[dfcountzeros[p] == 0.0]\n",
    "    print (\"percent zero value:\", 100*( float(len(dfcountzeros))/len(df2) )    )\n",
    "    print ()\n",
    "    \n",
    "#dfcountzeros = df2.copy()\n",
    "#dfcountzeros = dfcountzeros[dfcountzeros[\"Lot Area (sqft)\"] == 0.0].reset_index(drop=True)    \n",
    "#print (\"percent:\", 100*( float(len(dfcountzeros))/len(df2) )    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origzones = sorted(list(set(df2[\"Zoning District\"] )))\n",
    "#origzones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index(drop=True)\n",
    "df2[\"Zoning District\"] = df2[\"Zoning District\"].astype(str)\n",
    "df2[\"Zoning District2\"] = df2['Zoning District'].str.split(\"-\").str[0]\n",
    "\n",
    "\n",
    "zonedic = {'C1':'C_Local_Retail_Service',\n",
    "          'C2':'C_Local_Retail_Service',\n",
    "          'C3':'C_Waterfront_Recreation',\n",
    "          'C3A':'C_Waterfront_Recreation',\n",
    "          'C4':'C_Contextual_Non_Contextual_General',\n",
    "          'C5':'C_Restricted',\n",
    "          'C6':'C_General_Central',\n",
    "          'C7':'C_Ammusement', \n",
    "          'C8':'C_General_Service',\n",
    "          'M1':'M_Light',\n",
    "          'M2':'M_Medium',\n",
    "          'M3':'M_Heavy',\n",
    "           \n",
    "           \n",
    "          'R1':'R_Low_Density_Non_Contextual',\n",
    "           'R2':'R_Low_Density_Non_Contextual',\n",
    "           'R2A':'R_Low_Density_Non_Contextual',\n",
    "           'R2X':'R_Low_Density_Non_Contextual',\n",
    "           'R3':'R_Low_Density_Non_Contextual',\n",
    "           'R3A':'R_Low_Density_Non_Contextual',\n",
    "           'R3X':'R_Low_Density_Non_Contextual',\n",
    "           \n",
    "           'R4':'R_Low_Density_Non_Contextual',\n",
    "           'R4A':'R_Low_Density_Non_Contextual',\n",
    "           'R4B':'R_Low_Density_Non_Contextual',\n",
    "           \n",
    "           'R5':'R_Low_Density_Non_Contextual',\n",
    "           'R5A':'R_Low_Density_Non_Contextual',\n",
    "           'R5B':'R_Low_Density_Non_Contextual',\n",
    "           'R5D':'R_Low_Density_Non_Contextual',\n",
    "           \n",
    "           'R6':'R_Medium_Density_Non_Contextual',\n",
    "           'R6A':'R_Medium_Density_Non_Contextual',\n",
    "           'R6B':'R_Medium_Density_Non_Contextual',\n",
    "\n",
    "          'R7':'R_Medium_Density_Non_Contextual',\n",
    "           'R7A':'R_Medium_Density_Non_Contextual',\n",
    "           'R7B':'R_Medium_Density_Non_Contextual',\n",
    "           'R7D':'R_Medium_Density_Non_Contextual',\n",
    "           'R7X':'R_Medium_Density_Non_Contextual',\n",
    "           \n",
    "           'R8':'R_Medium_Density_Non_Contextual',\n",
    "           'R8A':'R_Medium_Density_Non_Contextual',\n",
    "           'R8B':'R_Medium_Density_Non_Contextual',\n",
    "           'R8X':'R_Medium_Density_Non_Contextual',\n",
    "           \n",
    "              \n",
    "           'R9':'R_High_Density_Non_Contextual',\n",
    "           'R9A':'R_High_Density_Non_Contextual',\n",
    "           'R9D':'R_High_Density_Non_Contextual',\n",
    "           'R9X':'R_High_Density_Non_Contextual',\n",
    "           \n",
    "           'R10':'R_High_Density_Non_Contextual',\n",
    "           'R10A':'R_High_Density_Non_Contextual',\n",
    "           'R10X':'R_High_Density_Non_Contextual',\n",
    "         \n",
    "\n",
    "          }\n",
    "\n",
    "df2[\"Zoning District2\"] = df2[\"Zoning District2\"].map(zonedic)\n",
    "df2[\"Zoning District2\"] =  df2[\"Zoning District2\"].astype(str)\n",
    "\n",
    "zoning = sorted(list(set(df2[\"Zoning District2\"].tolist() )))\n",
    "\n",
    "\n",
    "for i in range(0, len(df2)):\n",
    "    if \"/\" in df2[\"Zoning District\"][i]:\n",
    "        df2[\"Zoning District2\"][i] = \"M_Light_R_Low_Medium_Density_Non_Contextual\"\n",
    "\n",
    "\n",
    "#zoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "subset = ['Job Number','BIN Number', \"Borough Name\", \"Job Location House Number\", \"Job Location Street Name\",   \n",
    "          'Boiler', 'Mechanical', 'Plumbing', 'Standpipe', 'Construction Equipment', 'General Construction', 'Curb Cut',\n",
    "         'Proposed Occupancy Classification Description',\n",
    "         'Primary Structural System Description', 'Community Board','Zoning District2',\n",
    "         'Proposed Lot Detail : Lot Type Description',\n",
    "          'Enclosed Parking (Y/N)', 'Yard Flag (Y/N)', \n",
    "          'Stories Category', 'Applicant Name', 'Plan Exam Count', \"EstFeeLogNorm\", \n",
    "          \"ZoningFloorLogNorm\", \"DwellUnitsLogNorm\", \"FARLogNorm\"]\n",
    "\n",
    "df3 = df3[subset]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df3.columns:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(path + \"Long Duration Category Analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#those = sorted(list(set(df3[\"Proposed Lot Detail : Lot Type Description\"].tolist() )))\n",
    "#those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE OUTCOME VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('chained_assignment', None)\n",
    "\n",
    "len(df)\n",
    "\n",
    "#df2[\"LongDur\"] = 0\n",
    "\n",
    "#for i in range(0, len(df)):\n",
    "#    if df[\"bussDays\"][i] > 30:\n",
    "#        df[\"LongDur\"][i] = 1\n",
    "\n",
    "def LongDur(x):\n",
    "    if x <= 5:\n",
    "        return 0\n",
    "    if x > 5:\n",
    "        return 1\n",
    "\n",
    "df3[\"Outcome\"] = df3[\"Plan Exam Count\"].apply(LongDur)\n",
    "       \n",
    "        \n",
    "print (\"len of df\", len(df3))\n",
    "print (\"number of long dur\", df3[\"Outcome\"].sum())\n",
    "print (\"percent long dur\", float(df3[\"Outcome\"].sum())/len(df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"Lot Area (sqft)\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.to_csv(path + \"Plan Exam Count.csv\", index=False)\n",
    "df3.to_csv(path + \"Long Duration Category Analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLICANT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM SORT AND UPSAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal=df3.copy()\n",
    "#dfinal = dfinal.rename(columns={'Appointment Count': 'Plan Exam Count'})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = df2[df2.Outcome==0]\n",
    "df_minority = df2[df2.Outcome==1]\n",
    "\n",
    "print (\"Size of majority class\", len(df_majority) )\n",
    "print (\"Size of minority class\", len(df_minority) )\n",
    "\n",
    "lenMajority = len(df_majority)\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=lenMajority, # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "print ( \"Size of minority class upsampled\", len(df_minority_upsampled) )\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df2 = pd.concat([df_majority, df_minority_upsampled])\n",
    "df2 = df2.reset_index(drop=True)\n",
    " \n",
    "print ( \"Display new class counts\" )\n",
    "df2.Outcome.value_counts()\n",
    "\n",
    "df2 = df2.fillna(0)\n",
    "\n",
    "print (\"Display new class counts\" )\n",
    "df2.Outcome.value_counts()\n",
    "\n",
    "\"\"\"\n",
    "print (\"Randomly sort dfinal\" )\n",
    "dfinal[\"Index\"] = dfinal.index\n",
    "dfinal = dfinal.sample(frac=1)\n",
    "dfinal = dfinal.reset_index(drop=True)\n",
    "\n",
    "print (\"Size of final dataset \", len(dfinal) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE DUMMIES AND BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.to_csv(path + \"Long Job Duration BIS 3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"EstFeeCat\"] = df[\"J_TOTAL_ESTIMATED_FEE\"].apply(EstimatedFee)\n",
    "categories = set(df[\"FARCat\"].tolist() )\n",
    "print (categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfinal = df3.copy()\n",
    "\n",
    "\n",
    "#dfinal = dfinal.drop('Enclosed Parking (Y/N)', 1)\n",
    "#dfinal = dfinal.drop('Yard Flag (Y/N)', 1)\n",
    "#dfinal = dfinal.drop('Plan Examiner BIS Name', 1)\n",
    "\n",
    "def MakeDummies(df):\n",
    "    print (\"Parking and yard flags\")\n",
    "    df[\"Enclosed Parking (Y/N)\"] = df[\"Enclosed Parking (Y/N)\"].str.replace('Y', '1')\n",
    "    df[\"Enclosed Parking (Y/N)\"] = df[\"Enclosed Parking (Y/N)\"].str.replace('N', '0')\n",
    "    df[\"Enclosed Parking (Y/N)\"] = df[\"Enclosed Parking (Y/N)\"].astype(int)\n",
    "\n",
    "    df[\"Yard Flag (Y/N)\"] = df[\"Yard Flag (Y/N)\"].str.replace('Y', '1')\n",
    "    df[\"Yard Flag (Y/N)\"] = df[\"Yard Flag (Y/N)\"].str.replace('N', '0')\n",
    "    df[\"Yard Flag (Y/N)\"] = df[\"Yard Flag (Y/N)\"].astype(int)\n",
    "    \n",
    "    \"\"\"\n",
    "    print (\"Estimated fee\")\n",
    "    dummies = pd.get_dummies(df[\"EstFeeCat\"],prefix='F' )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('EstFeeCat', 1)\n",
    "    df = df.drop('J_TOTAL_ESTIMATED_FEE', 1)\n",
    "    \n",
    "    print (\"Proposed zoning floor area\")\n",
    "    dummies = pd.get_dummies(df[\"FloorAreaCat\"],prefix='FA' )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('FloorAreaCat', 1)\n",
    "    df = df.drop('Proposed Zoning Floor area', 1)\n",
    "    \n",
    "    print (\"Proposed dwelling units\")\n",
    "    dummies = pd.get_dummies(df[\"DwellingUnitCat\"],prefix='DU' )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('DU_0', 1)\n",
    "    df = df.drop('DwellingUnitCat', 1)\n",
    "    df = df.drop('Proposed Dwelling Units', 1)\n",
    "    \n",
    "    print (\"FAR\")\n",
    "    dummies = pd.get_dummies(df[\"FARCat\"],prefix='FAR' )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('FARCat', 1)\n",
    "    df = df.drop('Floor Area Ratio (FAR)  Floor Area', 1)\n",
    "    \n",
    "    #df[\"FARCat\"] = df[\"Floor Area Ratio (FAR)  Floor Area\"].apply(FAR)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    print (\"Occupancy classification\")\n",
    "    dummies = pd.get_dummies(df[\"Proposed Occupancy Classification Description\"],prefix='O' )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('Proposed Occupancy Classification Description', 1)\n",
    "\n",
    "    print (\"Building materials\")\n",
    "    dummies = pd.get_dummies(df[\"Primary Structural System Description\"],prefix='S' )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('Primary Structural System Description', 1)\n",
    "\n",
    "    print (\"Zoning\")\n",
    "    dummies = pd.get_dummies(df[\"Zoning District2\"],prefix='Z' )\n",
    "    dummies = dummies.drop('Z_nan', 1)\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('Zoning District2', 1)\n",
    "\n",
    "    print (\"Lot detail\")\n",
    "    dummies = pd.get_dummies(df[\"Proposed Lot Detail : Lot Type Description\"],prefix='L' )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('Proposed Lot Detail : Lot Type Description', 1)\n",
    "\n",
    "\n",
    "    print (\"Stories category\")\n",
    "    dummies = pd.get_dummies(df[\"Stories Category\"] )\n",
    "    print (len(dummies), len(df))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('Stories Category', 1)\n",
    "\n",
    "    \"\"\"\n",
    "    print (\"Applicants\")\n",
    "    dfapp = df[[ \"Applicant Name\", \"Appointment Count\"] ]\n",
    "    dfapp[\"Applicant Name\"] = dfapp[\"Applicant Name\"].map(str.strip)\n",
    "    dfapp[\"Job Count\"] = 1\n",
    "    dfapp = dfapp.groupby(['Applicant Name']).sum()\n",
    "    dfapp = dfapp.add_suffix('').reset_index()\n",
    "\n",
    "    #print (dfapp[\"Job Count\"].describe())\n",
    "\n",
    "    dfapp[\"Average Appointment Count\"] = dfapp[\"Appointment Count\"]/dfapp[\"Job Count\"]\n",
    "\n",
    "    applicantKeepList = []\n",
    "\n",
    "    for i in range(0, len(dfapp)):\n",
    "        if dfapp[\"Job Count\"][i] > 10:\n",
    "            applicantKeepList.append(dfapp[\"Applicant Name\"][i])\n",
    "\n",
    "    dummies = pd.get_dummies(df[\"Applicant Name\"])\n",
    "    print (\"dummies shape:\", dummies.shape)\n",
    "    dummies = dummies[applicantKeepList]\n",
    "    print (\"dummies shape:\", dummies.shape)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    df = df.drop('Applicant Name', 1)\n",
    "\n",
    "    #print (\"df shape:\",df.shape )\n",
    "\n",
    "\n",
    "\n",
    "    print (\"Community board\")\n",
    "    df[\"Community Board\"] = df[\"Community Board\"].astype(str)\n",
    "    df[\"Community Board\"] = df[\"Community Board\"].str.split(\".\").str[0]\n",
    "    dfcb = df[[ \"Community Board\"] ]\n",
    "    dfcb[\"Community Board\"] = dfcb[\"Community Board\"].astype(str).map(str.strip)\n",
    "    dfcb[\"Job Count\"] = 1\n",
    "    dfcb = dfcb.groupby(['Community Board']).sum()\n",
    "    dfcb = dfcb.add_suffix('').reset_index()\n",
    "\n",
    "    #dfcb[\"Average Appointment Count\"] = dfcb[\"Plan Exam Count\"]/dfcb[\"Job Count\"]\n",
    "    cbKeepList = []\n",
    "    for i in range(0, len(dfcb)):\n",
    "        if dfcb[\"Job Count\"][i] > 10:\n",
    "            cbKeepList.append(dfcb[\"Community Board\"][i])\n",
    "\n",
    "    dummies = pd.get_dummies(df[\"Community Board\"])\n",
    "    print (\"dummies shape:\", dummies.shape)\n",
    "    dummies = dummies[cbKeepList]\n",
    "    print (\"dummies shape:\", dummies.shape)        \n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop('Community Board', 1)\n",
    "    print (\"df shape:\",df.shape )\n",
    "\n",
    "    df = df.drop('Plan Exam Count', 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dfinal = MakeDummies(dfinal)\n",
    "#print ()\n",
    "#print (\"X_test shape:\", dfinal.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropVars(df):\n",
    "    df = df.drop('Index', 1)\n",
    "    df = df.drop('Job Number', 1)\n",
    "    df = df.drop('BIN Number', 1)\n",
    "    df = df.drop('Borough Name', 1)\n",
    "    df = df.drop('Job Location House Number', 1)\n",
    "    df = df.drop('Job Location Street Name', 1)\n",
    "    \n",
    "    #df = df.drop('Proposed Zoning Floor area', 1)\n",
    "    #df = df.drop('Lot Area (sqft)', 1)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "    \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "#create data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    \n",
    "model_selection = []\n",
    "    \n",
    "def AccuracyAndAUC(model, clf, X_test, y_test, a, b):\n",
    "    a = \"(\" + a + \",\"\n",
    "    b = b + \")\"\n",
    "    accuracy_param = a + b\n",
    "    clf_predicted = clf.predict(X_test)\n",
    "        \n",
    "    pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    roc=roc_auc_score(y_test, pred_prob)\n",
    "    #print ('AUC:', round(roc, 2))\n",
    "\n",
    "        \n",
    "    #clf_predicted = clf.predict(X_test)\n",
    "    #confusion = confusion_matrix(y_test, clf_predicted)\n",
    "\n",
    "    #print('Classifier Confusion Matrix\\n', confusion)\n",
    "    #print()\n",
    "        \n",
    "    model_selection.append([model,accuracy_param, clf.score(X_train, y_train), accuracy_score(y_test, clf_predicted),\n",
    "                               precision_score(y_test, clf_predicted),recall_score(y_test, clf_predicted), \n",
    "                                f1_score(y_test, clf_predicted), roc])\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "y = dfinal[\"Outcome\"]\n",
    "X = dfinal.drop('Outcome', 1)\n",
    "#X = X.drop('Bin', 1)\n",
    "#X = X.drop('CB Number', 1)\n",
    "\n",
    "#Create training, validation and test datasets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "lengthdf2 = int(len(df2))\n",
    "lengthdf2_20perc = int(lengthdf2*0.20)\n",
    "lengthdf2_60perc = int(lengthdf2*0.60)\n",
    "\n",
    "print (lengthdf2_60perc)\n",
    "print (lengthdf2_20perc)\n",
    "\n",
    "y_train = y[0:lengthdf2_60perc]\n",
    "X_train = X[0:lengthdf2_60perc]\n",
    "X_train = DropVars(X_train)\n",
    "\n",
    "y_test = y[lengthdf2_60perc:lengthdf2_60perc + lengthdf2_20perc]\n",
    "X_test = X[lengthdf2_60perc:lengthdf2_60perc + lengthdf2_20perc]\n",
    "X_test = DropVars(X_test)\n",
    "\n",
    "X_hold = X[lengthdf2_60perc + lengthdf2_20perc:]\n",
    "y_hold = y[lengthdf2_60perc + lengthdf2_20perc:]\n",
    "\n",
    "print (\"Make original data for holdout to merge later with holdout results\")\n",
    "holdOrigData = df3[lengthdf2_60perc + lengthdf2_20perc:]\n",
    "\n",
    "\n",
    "#test baseline using dummy classifier\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "    \n",
    "print (\"Baseline Accuracy: Dummy majority score:\", round(dummy_majority.score(X_test, y_test), 2) )\n",
    "print ()\n",
    "\n",
    "print (\"IMPLEMENT GBT MODELS\")\n",
    "\n",
    "\n",
    "#GRADIENT BOOSTED DECISION TREES\n",
    "print (\"GRADIENT BOOSTED DECISION TREES\")\n",
    "print (\"Gradient boosting default parameters\")\n",
    "clf = GradientBoostingClassifier(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "model = \"Gradient Boosted Dec Trees\"\n",
    "a = \"default\"\n",
    "b = \"default\"\n",
    "AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "#PlotROC(clf, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print ()\n",
    "print (\"GBT\")\n",
    "print (\"Adjusting gradient boosted learning rate and depth\")\n",
    "learn_rate = [0.01, 0.04, 0.06, 0.08, 0.1, 0.2,0.4, 0.6]\n",
    "max_depth = [2,4, 6]\n",
    "    \n",
    "for learn in learn_rate:\n",
    "    for depth in max_depth:\n",
    "        clf = GradientBoostingClassifier(learning_rate = learn, max_depth = depth, random_state = 0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        a = \"learning rate:\" + str(learn)\n",
    "        b = \"maximum depth:\" + str(depth)\n",
    "        AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "\"\"\"\n",
    "\n",
    "print (\"Neural networks\")\n",
    "#hidden_layers = [(10), (20), (30), (40), (50), (60), (70), (80), (90), (100) ]\n",
    "\n",
    "#hidden_layers = [(100,100,100) ]\n",
    "\n",
    "hidden_layers = [(10), (20), (30), (40), (50), (60), (70), (80), (90), (100), (150), (200),\n",
    "                 (10,10), (20,20), (30,30), (40,40), \n",
    "                 (50,50), (60,60), (70,70),\n",
    "                 (10,10,10), (20,20,20), (30,30,30), \n",
    "                 (40,40,40), (50,50,50), (60,60,60), (70,70,70)]\n",
    "\n",
    "#hidden_layers = [(20),  (40),(60), (80), (100), (120), (140), (160), (180), (200),\n",
    "#                 (20,20), (40,40), (60,60), (80,80), (100,100), (120,120), (140,140), (160,160), (180, 180), (200,200),\n",
    "#                (20,20,20), (40,40,40), (60,60,60), (80,80,80), (100,100,100), (120,120,120), (140,140,140), (160,160,160),\n",
    "#                (180,180, 180), (200, 200, 200), (250, 250, 250),(300, 300, 300)  ]\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "#NEURAL NETWORKS\n",
    "print (\"Neural Networks\")\n",
    "\n",
    "for layer in hidden_layers:\n",
    "    clf = MLPClassifier(hidden_layer_sizes = layer, max_iter=iterations) \n",
    "    clf.fit(X_train, y_train)\n",
    "    modelstr = \"Neural Networks\"\n",
    "    a = str(layer)\n",
    "    b = str(iterations)\n",
    "    print (modelstr, a)\n",
    "    AccuracyAndAUC(modelstr, clf, X_test, y_test, a, b)\n",
    "       \n",
    "\"\"\"     \n",
    "\n",
    "\n",
    "df_model = pd.DataFrame(model_selection, columns=('Model','Parameters', 'Training Score', 'Test Score', 'Precision', 'Recall', 'F1', 'AUC'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.sort_values(by = 'Recall', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_model[\"Diff\"] = df_model[\"Training Score\"] - df_model[\"Test Score\"]\n",
    "#df_model = df_model.sort_values(by = 'Diff', ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnRate = 0.04\n",
    "mDepth = 4\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate = learnRate, max_depth = mDepth, random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, clf.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "    #print (feature, importance)\n",
    "    \n",
    "x = pd.DataFrame(list(feats.items()),columns = ['Feature','Importance']) \n",
    "\n",
    "x = x.sort_values(by = 'Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "#for i in range(0, len(x)):\n",
    "#    print (x[\"Feature\"][i], x[\"Importance\"][i].round(3))\n",
    "\n",
    "x2 = x[x[\"Importance\"] > 0.01]\n",
    "\n",
    "importantfeatures = x2[\"Feature\"].tolist()\n",
    "\n",
    "\n",
    "x[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(path + \"Long Duration Job FINAL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS ON HOLDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.copy()\n",
    "y_train2 = y_train.copy()\n",
    "\n",
    "y_hold2 = y_hold.copy()\n",
    "X_hold2 = X_hold.copy()\n",
    "X_hold2 = DropVars(X_hold2)\n",
    "#X_hold2 = X_hold2.drop('Index', 1)\n",
    "#X_hold2 = X_hold2.drop('Job Number', 1)\n",
    "#X_hold2 = X_hold2.drop('BIN Number', 1)\n",
    "#X_hold2 = X_hold2.drop('Borough Name', 1)\n",
    "#X_hold2 = X_hold2.drop('Job Location House Number', 1)\n",
    "#X_hold2 = X_hold2.drop('Job Location Street Name', 1)\n",
    "\n",
    "#X_hold2 = DropFields(X_hold2)\n",
    "print (\"Training shape\",X_train2.shape )\n",
    "#X_hold_raw = X_hold.copy()\n",
    "#X_hold2 = X_hold.copy()\n",
    "#X_hold = df_hold.copy()\n",
    "#y_hold2 = X_hold2[\"Outcome\"]\n",
    "#X_hold2 = X_hold2.drop('Outcome', 1)\n",
    "#print (\"Reducing number of features\")\n",
    "#X_hold2 = X_hold2[importantfeatures]\n",
    "print (\"Holdout shape\",X_hold2.shape )\n",
    "\n",
    "\n",
    "#Gradient Boosted Trees\n",
    "clf = GradientBoostingClassifier(learning_rate = learnRate, max_depth = mDepth, random_state = 0)\n",
    "#clf = MLPClassifier(hidden_layer_sizes = (70), max_iter=1000) \n",
    "\n",
    "\n",
    "clf.fit(X_train2, y_train2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf_predicted = clf.predict(X_hold2)\n",
    "confusion = confusion_matrix(y_hold2, clf_predicted)\n",
    "print (\"Confusion Matrix\")\n",
    "print (confusion)\n",
    "\n",
    "\n",
    "print (\"Calculate predictions using best model\")\n",
    "result  =   clf.predict_proba(X_hold2)\n",
    "#assign positive class probability predictions\n",
    "    \n",
    "X_hold2[\"PredProb\"] = result[:,1]\n",
    "\n",
    "X_hold2 = pd.concat([X_hold2, y_hold2], axis=1)\n",
    "\n",
    "print (\"create predicted outcome\")\n",
    "X_hold2[\"PredOutcome\"] = 0\n",
    "\n",
    "X_hold2[\"Index\"] = X_hold2.index\n",
    "X_hold2 = X_hold2.reset_index(drop=True)\n",
    "\n",
    "for i in range(0, len(X_hold2)):\n",
    "    if X_hold2[\"PredProb\"][i] >= 0.5:\n",
    "        X_hold2[\"PredOutcome\"][i] = 1\n",
    "        \n",
    "print (\"DONE\")\n",
    "\n",
    "#print (clf)\n",
    "print (\"Size of final test data (holdout data):\", len(X_hold2))\n",
    "print (\"True positive:\", sum(confusion[1]) )\n",
    "print (\"True negative:\", sum(confusion[0]) )\n",
    "print (\"Correct Predictions:\",confusion[1][1] )\n",
    "print (\"Percent correctly predicted:\",round(float(confusion[1][1])/sum(confusion[1]), 2) )\n",
    "print (\"False negatives:\", confusion[1][0])\n",
    "print (\"Percent false negatives:\",  round(confusion[1][0]/sum(confusion[1]),2) )\n",
    "print (\"False positives:\", confusion[0][1] )\n",
    "print (\"Percent false positives:\", round(float(confusion[0][1])/len(X_hold2), 2) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Merge holdout datasets with predicted outcome with one with job number\")\n",
    "print (\"X Holdout\")\n",
    "print (holdOrigData.shape, X_hold2.shape)\n",
    "#print (\"Y Holdout\")\n",
    "#print (y_hold.shape, y_hold2.shape)\n",
    "mergeX_hold2 = X_hold2[[\"PredProb\", \"Outcome\", \"PredOutcome\",\"Index\"]]\n",
    "print (mergeX_hold2.shape)\n",
    "print (holdOrigData.shape)\n",
    "\n",
    "#output_holdout = X_hold.copy()\n",
    "holdOrigData = holdOrigData.reset_index(drop=True)\n",
    "output_holdout = pd.concat([holdOrigData, mergeX_hold2], axis=1)\n",
    "\n",
    "print (output_holdout.shape)\n",
    "\n",
    "output_holdout = output_holdout.drop_duplicates(['Job Number']).reset_index(drop=True)\n",
    "\n",
    "print (output_holdout.shape)\n",
    "\n",
    "\n",
    "#output_holdout.to_csv(path + \"Holdout Dataset Model Predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_holdout.to_csv(path + \"Long Dur Pred Holdout.csv\", index=False)\n",
    "X_hold2.to_csv(path + \"Long Dur Pred Holdout.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfinal.dtypes[:50], dfinal.dtypes[50:100], dfinal.dtypes[100:150], dfinal.dtypes[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
